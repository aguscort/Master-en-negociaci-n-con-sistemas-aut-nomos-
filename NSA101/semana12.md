# Semana 12: Utilidades Híbridas y Factores No Monetarios. Integración de objetivos no económicos en la función de utilidad de un agente (ej. tiempo, energía, reputación, alineación de valores). Introducción al vector de valores éticos (V) y su ponderación (α) en U(a; θ, V).

Como vimos la semana pasada, las **funciones de utilidad** son herramientas fundamentales para representar las preferencias de los agentes racionales sobre diferentes resultados. La **Teoría de la Utilidad Esperada de von Neumann-Morgenstern** (VNM) proporciona un marco riguroso para modelar decisiones bajo incertidumbre, donde la racionalidad implica maximizar la utilidad esperada de las loterías (resultados inciertos).

Sin embargo, los resultados o "acuerdos" rara vez se reducen a una única dimensión, como solo dinero. En situaciones del mundo real, los agentes se preocupan por una variedad de factores que pueden ser económicos o no económicos.

## Integración de Objetivos No Económicos en la Función de Utilidad
 
Las fuentes muestran que las funciones de utilidad pueden y de hecho representan preferencias sobre resultados definidos por **múltiples atributos**. Por ejemplo:

1.  **Múltiples Bienes:** Las preferencias pueden ser sobre "paquetes de bienes" (vectores en R`+). Una función de utilidad sobre un paquete de bienes asignaría un valor numérico a la combinación de diferentes cantidades de diversos bienes, reflejando cómo valora el agente esa combinación.
2.  **Tiempo y Precio:** En un mercado, un agente puede preocuparse tanto por el **precio (p)** como por el **momento (t)** en que se alcanza un acuerdo. Sus preferencias sobre pares (p, t) pueden representarse mediante una función de utilidad. Un enfoque común es utilizar un **factor de descuento (δt)**, donde δ es un factor entre 0 y 1, lo que significa que los resultados obtenidos más tarde (t más grande) tienen menos peso en la utilidad total, integrando así el tiempo como un costo o factor que reduce la utilidad. La utilidad para un vendedor podría ser δtp y para un comprador δt(1-p).
3.  **Asignación y Pago:** En mecanismos o juegos, la utilidad de un agente puede depender de la **asignación de bienes (q)** (que puede ser un vector multidimensional) y de un **pago (y)** (monetario). La función de utilidad puede tener una forma como ui(q, y, t) = vi(q, t) - yi, donde 'q' y 't' son atributos no monetarios (la asignación y el tipo privado del agente) y 'y' es monetario.
4.  **Tipos o Información Privada:** La utilidad de un agente a menudo depende de su **tipo (θ)**, que encapsula su información privada o sus características que afectan sus preferencias. Esto puede incluir sus valoraciones o cómo percibe los resultados. Por ejemplo, en el modelo cuasilineal, la utilidad del agente i con tipo θi para un resultado no monetario x puede representarse por una "valoración" vi(x), que depende de θi.
5.  **Costos No Monetarios:** La **complejidad** de una estrategia o la implementación puede incorporarse como una desutilidad (costo) en la función de utilidad del agente. Esto es un ejemplo directo de un factor no económico (costo computacional o cognitivo) afectando la utilidad.
6.  **Resultados No Monetarios en Modelos Cuasilineales:** Un marco particularmente útil para separar los aspectos monetarios de los no monetarios es la **utilidad cuasilineal**. Aquí, el conjunto de resultados se divide en una parte no monetaria (un conjunto finito de resultados X) y una parte monetaria (pagos). La utilidad de un agente i de tipo θ para un resultado o = (x, p) (donde x es un resultado no monetario y p es un pago) toma la forma ui(o, θ) = ui(x, θ) - fi(pi). Aquí, ui(x, θ) representa la utilidad derivada del resultado no monetario 'x' y del tipo 'θ', mientras que -fi(pi) es la desutilidad del pago 'pi'. En muchos casos, fi(pi) = pi (linealidad en el dinero), lo que implica **neutralidad al riesgo** y **utilidad transferible** en la parte monetaria. Esto permite enfocar el análisis de eficiencia en la parte no monetaria, maximizando la suma de las utilidades derivadas de 'x' a través de los agentes (∑i ui(x, θi) = ∑i vi(x)).

En resumen, las funciones de utilidad en los modelos presentados están diseñadas para ser lo suficientemente flexibles como para depender de múltiples dimensiones del resultado y de las características internas del agente (como su tipo), permitiendo así la inclusión de factores no económicos como el tiempo, las características de los bienes, la información privada del agente e incluso costos de complejidad.

## Vector de Valores Éticos (V) y su Ponderación (α)

La consulta plantea la introducción de una estructura de función de utilidad específica: U(a; θ, V), donde 'a' es la acción, 'θ' es el tipo del agente, 'V' es un **vector de valores éticos**, y 'α' es una ponderación para 'V'.

Al revisar las fuentes proporcionadas, se discuten ampliamente los conceptos de **valores**, **ética**, **moralidad** y **virtudes** en el contexto de agentes de inteligencia artificial (AMAs). Se explora cómo modelar la toma de decisiones éticas, la aparición de normas sociales en sistemas multiagente, la diferencia entre la "conducta" humana (arraigada en biología, subjetividad, conciencia) y la "actuación" de la IA (basada en algoritmos y datos), y los desafíos de programar la moralidad o las virtudes en las máquinas.

Se habla de la necesidad de que los AMAs tengan acceso a la información y "sabiduría" que los humanos adquieren a través de las emociones y la inteligencia emocional. Se mencionan los enfoques "de arriba hacia abajo" (principios, deberes) y "de abajo hacia arriba" (aprendizaje, evolución, emergencia) para la moralidad en las máquinas, sugiriendo que se necesitan enfoques híbridos. Algunos modelos intentan replicar la inteligencia general humana (AGI) integrando diversas influencias en las decisiones éticas, desde sentimientos hasta reglas. También se discuten las **virtudes** (sabiduría, coraje, moderación, justicia) como un tercer elemento de la teoría moral, aunque implementar esto computacionalmente es complejo.

Sin embargo, **ninguna de las fuentes proporcionadas introduce ni utiliza explícitamente una función de utilidad en el marco VNM con la forma U(a; θ, V)**, donde V es un vector formal de valores éticos distintos de otros atributos del resultado o del tipo del agente, ni discuten cómo un parámetro 'α' ponderaría la influencia de dicho vector V en la utilidad total de la manera propuesta.

Las fuentes sí muestran que la utilidad depende del tipo del agente (θ), y el tipo podría, en principio, incluir o estar relacionado con las "valoraciones" o preferencias del agente sobre resultados que implican cuestiones éticas o de valor. También muestran cómo las preferencias pueden depender de múltiples atributos del resultado (representado genéricamente como 'x' en o 'q' en), y algunos de estos atributos podrían *describir* aspectos del resultado relacionados con valores (por ejemplo, si un bien fue producido éticamente), lo que afectaría la utilidad ui(x, θ).

Pero la idea de separar explícitamente un **vector V de valores éticos** como un argumento separado en la función de utilidad U, con una ponderación específica (α), como un enfoque general para integrar valores éticos en la maximización de utilidad esperada de von Neumann-Morgenstern, no se presenta en los textos dados. La discusión sobre valores y ética en las fuentes se centra más en la naturaleza de la moralidad en los agentes, cómo modelarla (BDI, virtudes), o las implicaciones de la IA en los valores humanos, en lugar de formalizar los valores éticos *dentro* de la función de utilidad clásica U(resultado) o U(acción, estado, tipo) de un agente en el sentido VNM para la toma de decisiones bajo incertidumbre.
